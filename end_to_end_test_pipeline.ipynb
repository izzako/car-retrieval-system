{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "from transformers import AutoModelForObjectDetection, AutoImageProcessor, pipeline\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as models\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_objects_from_image(image: Image.Image, labels: list, padding: int = 10):\n",
    "    \"\"\"\n",
    "    Crops objects from an image using bounding boxes with optional padding.\n",
    "    \n",
    "    Args:\n",
    "        image (PIL.Image): The source image.\n",
    "        labels (list): List of dicts with 'box' key containing 'xmin', 'ymin', 'xmax', 'ymax'.\n",
    "        padding (int): Number of pixels to pad around the bounding box.\n",
    "        \n",
    "    Returns:\n",
    "        List[PIL.Image]: Cropped image patches.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    cropped_images = []\n",
    "\n",
    "    for obj in labels:\n",
    "            box = obj['box']\n",
    "            xmin = max(box['xmin'] - padding, 0)\n",
    "            ymin = max(box['ymin'] - padding, 0)\n",
    "            xmax = min(box['xmax'] + padding, width)\n",
    "            ymax = min(box['ymax'] + padding, height)\n",
    "\n",
    "            cropped = image.crop((xmin, ymin, xmax, ymax))\n",
    "            cropped_images.append(cropped)\n",
    "\n",
    "    return cropped_images\n",
    "\n",
    "def load_model(checkpoint_path, num_classes, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    # LOAD THE CLASSIFIER MODEL\n",
    "    model = models.mobilenet_v3_large()\n",
    "    model.classifier[3] = nn.Linear(in_features=1280, out_features=num_classes)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "font = ImageFont.truetype(\"./ARIAL.TTF\",size=20)\n",
    "def plot_results(image, results, threshold=0.6):\n",
    "    image = Image.fromarray(np.uint8(image))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    width, height = image.size\n",
    "\n",
    "    for result in results:\n",
    "        score = result[\"score\"]\n",
    "        label = result[\"label\"]\n",
    "        box = list(result[\"box\"].values())\n",
    "        if label in ['motorcycle','autorickshaw']:\n",
    "            outline_color = 'red'\n",
    "        else:\n",
    "            outline_color = 'yellow'\n",
    "        if score > threshold:\n",
    "            x1, y1, x2, y2 = tuple(box)\n",
    "            draw.rectangle((x1, y1, x2, y2), outline=outline_color, width=3)\n",
    "            draw.text((x1 + 5, y1 - 20), label, fill=\"white\",font=font)\n",
    "            draw.text((x1 + 5, y1 + 10), f\"{score:.2f}\", fill=\"green\" if score > 0.7 else \"red\")\n",
    "\n",
    "    return image\n",
    "\n",
    "def infer_image(model, image: Image.Image, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    transform_x = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    class_names={\n",
    "        0: 'Coupe',\n",
    "        1: 'Sedan',\n",
    "        2: 'Cab',\n",
    "        3: 'Convertible',\n",
    "        4: 'SUV',\n",
    "        5: 'Minivan',\n",
    "        6: 'Hatchback',\n",
    "        7: 'Other',\n",
    "        8: 'Van',\n",
    "        9: 'Wagon'\n",
    "    }\n",
    "    input_tensor = transform_x(image).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        predicted_class = output.argmax(dim=1).item()\n",
    "\n",
    "    return class_names[predicted_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Video -> Image frames\n",
    "First, download and convert the video from the google drive to images as folders to video using `python source_code/processor/vid_img_converter.py` with below settings:\n",
    "- `IS_DOWNLOAD=True`\n",
    "- `FRAME_DIR = \"data/frame_dir\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Object Detection on Image Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"./data/frame_dir\"\n",
    "json_output_folder = \"./output/frame_json\"\n",
    "batch_size = 8  # adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Create output folder\n",
    "os.makedirs(json_output_folder, exist_ok=True)\n",
    "\n",
    "# üì¶ Load pipeline\n",
    "\n",
    "# Load processor and model manually\n",
    "processor = AutoImageProcessor.from_pretrained(\"izzako/detr-resnet-50-finetuned-IDD_Detection\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    \"izzako/detr-resnet-50-finetuned-IDD_Detection\",\n",
    "    torch_dtype=\"auto\",          # Let HF decide best dtype\n",
    "    device_map=\"auto\"            # Avoid meta tensor issues\n",
    ")\n",
    "\n",
    "# Build the pipeline\n",
    "obj_detector = pipeline(\n",
    "    \"object-detection\",\n",
    "    model=model,\n",
    "    image_processor=processor,\n",
    "    # device=0  # or -1 for CPU\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Load image paths\n",
    "image_paths = sorted(list(Path(image_folder).glob(\"*.jpg\")))\n",
    "\n",
    "\n",
    "# üîÅ Batch inference and save to JSON\n",
    "for i in tqdm(range(0, len(image_paths), batch_size),):\n",
    "    \n",
    "    batch_paths = image_paths[i:i+batch_size]\n",
    "    batch = [Image.open(p).convert(\"RGB\") for p in batch_paths]\n",
    "    results = obj_detector(batch)\n",
    "\n",
    "    for path, prediction in zip(batch_paths, results):\n",
    "        filename = Path(path).stem + \".json\"\n",
    "        output_path = Path(json_output_folder) / filename\n",
    "\n",
    "        # üìù Save prediction to JSON\n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(prediction, f, indent=2)\n",
    "\n",
    "        # print(f\"‚úÖ Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Car Classifier on Detected Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./output/mobilenet_v3_large_checkpoint_10.pth\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"./data/frame_dir\"\n",
    "detection_folder = \"./output/frame_json\"\n",
    "batch_size = 8  # adjust as needed\n",
    "\n",
    "\n",
    "# RENAME DETECTED IMAGE TO CAR TYPE USING CLASSIFIER\n",
    "labeled_folder =  \"../output/frame_label\"\n",
    "os.makedirs(labeled_output_folder,exist_ok=True)\n",
    "\n",
    "for j,label in enumerate(tqdm(sorted(os.listdir(label_folder)))):\n",
    "    results = json.load(open(os.path.join(label_folder,label),'r'))\n",
    "    image = Image.open(os.path.join(image_folder,sorted(os.listdir(image_folder))[j]))\n",
    "    cropped_imgs = crop_objects_from_image(image=image, labels=results, padding=20)\n",
    "    for i,result in enumerate(results):\n",
    "        if result['label']!='car':continue\n",
    "        pred_label = infer_image(model, cropped_imgs[i])\n",
    "        result['label']=pred_label\n",
    "\n",
    "    with open(os.path.join(detection_folder,label), \"w\") as f:\n",
    "        json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5920 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5920/5920 [03:49<00:00, 25.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# PLOT THE CLASSIFIER RESULT TO IMAGES WITH BOUNDING BOX\n",
    "\n",
    "label_folder = \"./output/frame_label\"\n",
    "rec_plotted_img =  \"./output/pred_image\"\n",
    "\n",
    "os.makedirs(rec_plotted_img,exist_ok=True)\n",
    "for i in tqdm(range(len(os.listdir(label_folder)))):\n",
    "    image_name=sorted(os.listdir(image_folder))[i]\n",
    "    image = Image.open(os.path.join(image_folder,image_name))\n",
    "    results = json.load(open(os.path.join(label_folder,sorted(os.listdir(label_folder))[i]),'r'))\n",
    "    plot_results(image, results, threshold=0.5).save(os.path.join(rec_plotted_img,image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predicted Frames to Video\n",
    "then, convert the `./output/pred_image` folders to video using `python source_code/processor/vid_img_converter.py` with below settings:\n",
    "- `IS_DOWNLOAD=False`\n",
    "- `PRED_FRAME_DIR = \"./output/pred_image\"`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
